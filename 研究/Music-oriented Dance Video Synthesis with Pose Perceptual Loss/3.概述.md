## 3.概述

为了从音乐中产生舞蹈视频，我们将系统分为两个阶段。在第一阶段，我们提出了一个端到端模型，该模型根据音频输入直接生成舞蹈骨架序列。在第二阶段，我们应用改进的pix2pixHD GAN，将舞蹈骨架序列转移到舞蹈视频中。在本概述中，我们将主要描述第一阶段，如图2所示。

![img](图2.png)

##### 图2：我们的人类骨架序列合成框架。 输入是音乐信号，分为0.1秒的音乐。 该生成器包含一个音频编码器，一个双向GRU和一个姿态生成器。 生成器的输出骨架序列与音乐一起被馈送到全局内容鉴别器。 然后将生成的骨架序列划分为重叠的子序列，这些子序列被馈送到局部时间区分符中。

令V为人体骨骼的关节数，二维坐标（x，y）的维数为2。我们将舞蹈骨骼序列X表示为总共T个连续帧中的人体骨骼序列：![img](http://latex.codecogs.com/gif.latex?\&space;X\in&space;R^{T\times2V})，其中每个骨架![img](http://latex.codecogs.com/gif.latex?\&space;X_t\in&space;R^{2V})是一个包含所有（x，y）关节位置的向量。 我们的目标是学习函数![img](http://latex.codecogs.com/gif.latex?\&space;G:R^{TS}\rightarrow&space;R^{T\times2V})，该函数将每帧采样率S的音频信号映射到联合位置矢量序列。

### 生成器

### 局部时间判别器

### 全局内容判别器

### 姿势感知损失

![img](图3.png)

##### 图3：基于ST-GCN的姿势感知损失概述。G是第一阶段的发电机。y是地面真理骨架序列，而yˆ是生成的骨架序列。

---


![img](http://latex.codecogs.com/gif.latex?\&space;)


&space;

\times