# 环境准备
- python 3.7
- cuda 9.0
- cuDNN v7.6.2
- `pip install ffmpeg`
- `pip install -r requirments.txt`

创建conda python3.7环境：
```
cd jupyterFile\LearningIndividualStylesOfConversationalGesture
```
```
conda create --name LearningIndividualStylesOfConversationalGesture_env_py3-7 python=3.7 anaconda
```

启动conda：
```
activate LearningIndividualStylesOfConversationalGesture_env_py3-7
```

ffmpeg：
```
pip install FFmpeg
```

---

通过脚本下载YouTube数据 样式
```
python -m data.download.download_youtube --base_path </path/to/dataset base folder> --speaker <speaker_name>
```
实际
```
python -m speech2gesture.data.download.download_youtube --base_path F:\jupyterFile\LearningIndividualStylesOfConversationalGesture --speaker rock
```

提取训练数据：
```
python -m speech2gesture.data.train_test_data_extraction.extract_data_for_training --base_dataset_path F:\jupyterFile\LearningIndividualStylesOfConversationalGesture --speaker oliver
```

训练
```
python -m speech2gesture.audio_to_multiple_pose_gan.train --gans 1 --name test_run --arch_g audio_to_pose_gans --arch_d pose_D --speaker oliver --output_path /tmp
```























---
