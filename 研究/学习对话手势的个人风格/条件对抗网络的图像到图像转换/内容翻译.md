## 摘要

　　我们研究条件对抗网络作为图像到图像翻译问题的通用解决方案。

　　这些网络不仅学习从输入图像到输出图像的映射，而且学习损失函数来训练该映射。

　　这使得可以将相同的通用方法应用于传统上需要非常不同的损失公式的问题。

　　我们证明了这种方法可以有效地从标签图合成照片，从边缘图重建对象以及为图像着色等任务。 作为一个社区，我们不再需要手工设计映射功能，这项工作表明我们无需手工设计损失函数就可以取得合理的结果。

---

## 引言
 
　　图像处理，计算机图形学和计算机视觉中的许多问题都可被视为将输入图像“转换”为相应的输出图像。

　　正如可以用英语或法语表达概念一样，可以将场景渲染为RGB图像，梯度场，边缘图，语义标签图等。

　　与自动语言翻译类似，我们将自动图像到图像翻译定义为在给定足够的训练数据的情况下将场景的一种可能表示转换为另一种场景的问题（参见图1）。

　　语言翻译困难的一个原因是，语言之间的映射很少一对一映射，因此任何给定的概念都比另一种语言更易于表达。

　　同样，大多数图像到图像的翻译问题要么是多对一（计算机视觉）-将照片映射到边缘，片段或语义标签，要么是一对多（计算机图形）-映射标签或用户输入稀疏到逼真的图像。

　　传统上，这些任务中的每一项都是由单独的专用机器（例如[7、15、11、1、3、37、21、26、9、42、46]）处理的，尽管始终相同：根据像素预测像素。本文的目标是为所有这些问题开发一个通用框架。


## 相关工作

##### 图像建模的结构化损失

　　我们的条件GAN的不同之处在于损失是可学习的

##### 条件GAN

　　我们的框架的不同之处在于，没有什么是特定于应用程序的。这使我们的设置比大多数其他设置简单得多。

　　我们的生成器，我们使用基于“ U-Net”的体系结构[34]。

　　对于我们的鉴别器，我们使用卷积的“ PatchGAN”分类器，该分类器仅在图像补丁范围内惩罚结构。先前在[25]中提出了类似的PatchGAN架构，以获取本地样式统计信息。在这里，我们证明了这种方法对更广泛的问题有效，并且我们研究了更改补丁大小的效果。












---