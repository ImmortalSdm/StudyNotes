## 4. 实验
在本节中，我们评估ST-GCN在基于骨骼的动作识别实验中的性能。 我们在两个性质迥异的大型动作识别数据集上进行了实验：动力学人类动作数据集（Kinetics）（Kay等人，2017）是迄今为止最大的无约束动作识别数据集，以及NTURGB + D（Shahroudy等人，2016） 最大的内部捕获动作识别数据集。 特别是，我们首先在动力学数据集上进行详细的消融研究，以检查所提出的模型组件对识别性能的贡献。 然后，我们将ST-GCN的识别结果与其他最新方法和其他输入方式进行比较。 为了验证我们在无约束条件下获得的经验是否具有普遍性，我们在NTURGB + D上对约束条件进行了实验，并将ST-GCN与其他最新方法进行了比较。 所有实验均在带有8个TITAN X GPU的PyTorch深度学习框架上进行。

### 4.1 数据集和评估指标

#### Kinetics

Deepmind Kinetics人类动作数据集（Kay等，2017）包含从YouTube检索到的约300，000个视频剪辑。 这些视频涵盖了多达400种人类动作课程，从日常活动，运动场景到具有交互作用的复杂动作，不一而足。  Kinetics中的每个剪辑持续约10秒。此Kinetics数据集仅提供原始视频剪辑，而没有骨架数据。在这项工作中，我们专注于基于骨骼的动作识别，因此我们将像素坐标系中的估计关节位置用作我们的输入，并丢弃原始RGB帧。 

为了获得关节位置，我们首先将所有视频的大小调整为340×256的分辨率，然后将帧频转换为30 FPS。 然后，我们使用公共可用的OpenPose（Cao等人，2017b）工具箱来估计剪辑每一帧上18个关节的位置。该工具箱在像素坐标系中给出了2D坐标（X，Y），并给出了18个人体关节的置信度C。 因此，我们用（X，Y，C）元组表示每个关节，并将骨架框架记录为18个元组的数组。
对于多人案例，我们在每个片段中选择2个平均关节信心最高的人。 

这样，一个带有T帧的剪辑被转换为这些元组的骨架序列。 实际上，我们用张量为（3，T，18，2）的张量表示片段。

为简单起见，我们从头开始重播序列以填充T = 300，以填充每个剪辑。我们将在动力学上发布估计的关节位置以重现结果。

我们根据数据集作者的建议按top-1和top-5分类准确性评估识别性能（Kay等人2017）。数据集提供了240000个剪辑的训练集和20000个验证集。我们在训练集上训练比较的模型，并报告验证集的准确性。

#### NTU-RGB+D

### 4.2 消融研究

我们通过在Kinetics数据集上进行动作识别实验来检查ST-GCN中拟议组件的有效性（Kay等人2017）。

#### 时空图卷积

首先，我们评估使用时空图卷积运算的必要性。

我们使用基线网络体系结构（Kim and Reiter 2017），其中所有时空卷积仅由时间卷积代替。也就是说，我们将所有输入关节位置连接起来，以在每个帧t处形成输入特征。然后，时间卷积将对此输入进行运算，并随时间进行卷积。 我们将此模型称为“基准TCN”。 

众所周知，这种识别模型可以在约束数据集（例如NTU-RGB + D）上很好地工作（Kim and Reiter 2017）。 从表1中可以看出，具有时空图卷积的模型以及合理的划分策略，在动力学方面一直优于基线模型。 实际上，这种时间卷积相当于完全连接的联合图上具有未共享权重的空间时间图卷积。 因此，基线模型和ST-GCN模型之间的主要区别是稀疏的自然连接和卷积运算中的共享权重。 此外，我们评估了基线模型和ST-GCN之间的中间模型，称为“局部卷积”。 在此模型中，我们将稀疏联合图用作ST-GCN，但使用权重不共享的卷积滤波器。
我们相信基于ST-GCN的模型的更好性能可以证明基于骨架的动作识别中时空图卷积的强大功能。

#### 分区策略

在这项工作中，我们提出了三种分区策略：1）单标签；  2）距离划分；  3）空间配置分区。 我们使用这些分区策略评估ST-GCN的性能。
结果总结在表1中。我们观察到，具有多个子集的分区通常比单标签好得多。这与单标签的明显问题一致，即单标签相当于在卷积操作之前简单地对特征求平均。 鉴于此观察，我们将在距离划分和单标签之间的中间进行实验，称为“距离划分*”。 在此设置中，我们将距离分区中两个子集的权重绑定为仅因比例因子-1或w 0 = -w 1而不同。 与单标签相比，此设置仍可获得更好的性能，这再次证明了使用多个子集进行分区的重要性。 在多子集分区策略中，空间配置分区可实现更好的性能。
这证实了我们设计该策略的动机，该策略考虑了同心和偏心运动模式。 基于这些观察，我们在以下实验中使用空间配置分区策略。

#### 可学习的边缘重要性加权

### 4.3 与现有技术的比较

为了验证ST-GCN在无约束和约束环境下的性能，我们分别在Kinetics数据集（Kay等2017）和NTURGB + D数据集（Shahroudy等2016）上进行了实验。

#### Kinetics
在动力学上，我们比较了基于骨架的动作识别的三种特征方法。 第一种是针对手工特征的特征编码方法（Fernando等人，2015年），在表2中称为“特征编码”。我们还基于Kinetics实现了两种基于深度学习的方法，即Deep LSTM（Shahroudy等人，2015年）。  2016年）和时间ConvNet（Kim和Reiter，2017年）。
我们根据前1名和前5名的准确性比较了这些方法的识别性能。 在表2中，ST-GCN能够胜过以前的代表性方法。 作为参考，我们列出了使用RGB帧和光流进行识别的性能，如（Kay et al。
2017）。




























