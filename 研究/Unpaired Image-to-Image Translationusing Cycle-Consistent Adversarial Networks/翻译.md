## 摘要

Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs.<br/>
图像到图像的翻译是一类视觉和图形问题，其目标是使用对齐的图像对训练集来学习输入图像和输出图像之间的映射。

However, for many tasks,paired training data will not be available. <br/>
但是，对于许多任务，配对的训练数据将不可用。

We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples.<br/> 
我们提出了一种在没有配对示例的情况下学习将图像从源域X转换为目标域Y的方法。

Our goal is to learn a mapping G : X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss.<br/>
我们的目标是学习一个映射G：X→Y，使得来自G（X）的图像分布与D的分布使用对抗损失是无法区分的。

Because this mapping is highly under-constrained, we couple it with an inverse mapping F : Y → X and introduce a cycle consistency loss to enforce F (G(X)) ≈ X (and vice versa). <br/>
由于此映射的约束严重不足，因此我们将其与反映射F：Y→X耦合，并引入循环一致性损失以强制执行F（G（X））≈X（反之亦然）。

Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer,photo enhancement, etc. <br/>
定性结果在不存在配对训练数据的多个任务上显示，包括收集样式转移，对象变形，季节转移，照片增强等。

Quantitative comparisons against several prior methods demonstrate the superiority of our approach.<br/>
与几种先前方法的定量比较证明了我们方法的优越性。

---

## 引言

What did Claude Monet see as he placed his easel by the bank of the Seine near Argenteuil on a lovely spring day in 1873 (Figure 1, top-left)? 
克劳德·莫奈（Claude Monet）在1873年一个可爱的春天里，将画架放在塞纳河岸附近的阿根廷人附近时，看到了什么（图1，左上）？

A color photograph, had it been invented, may have documented a crisp blue sky and a glassy river reflecting it. 
如果发明了彩色照片，则可能记录了湛蓝的天空和反射着它的玻璃状河流。

Monet conveyed his impression of this same scene through wispy brush strokes and a bright palette.
莫奈通过细腻的笔触和明亮的调色板传达了他对同一场景的印象。

What if Monet had happened upon the little harbor in Cassis on a cool summer evening (Figure 1, bottom-left)?
如果莫奈在一个凉爽的夏日夜晚发生在卡西斯（Cassis）的小港口上，该怎么办（图1，左下）？

A brief stroll through a gallery of Monet paintings makes it possible to imagine how he would have rendered the scene: perhaps in pastel shades, with abrupt dabs of paint, and a somewhat flattened dynamic range.
短暂浏览莫奈画作的画廊，可以想象他将如何渲染场景：也许是柔和的阴影，突然的油漆点涂和动态范围平坦。

We can imagine all this despite never having seen a side by side example of a Monet painting next to a photo of the scene he painted. 
我们可以想象所有这一切，尽管从未在他所画的场景照片旁边看到莫奈画作的并排示例。

Instead, we have knowledge of the set of Monet paintings and of the set of landscape photographs.
我们可以想象所有这一切，尽管从未在他所画的场景照片旁边看到莫奈画作的并排示例。

We can reason about the stylistic differences between these two sets, and thereby imagine what a scene might look like if we were to “translate” it from one set into the other.
取而代之的是，我们了解了莫奈的绘画和风景照。

In this paper, we present a method that can learn to do the same: capturing special characteristics of one image collection and figuring out how these characteristics could be translated into the other image collection, all in the absence of any paired training examples.
我们可以推断出这两个集合之间的风格差异，从而可以想象如果将场景从一个集合“转换”到另一个集合中，场景将是什么样子。

This problem can be more broadly described as imageto-image translation [22], converting an image from one representation of a given scene, x, to another, y, e.g.,grayscale to color, image to semantic labels, edge-map to photograph. 
这个问题可以更广泛地描述为图像到图像的转换[22]，将图像从给定场景x的一种表示形式转换为另一种y，例如将灰度转换为颜色，将图像转换为语义标签，将边缘映射转换为照片。 。

Years of research in computer vision, image processing, computational photography, and graphics have produced powerful translation systems in the supervised setting, where example image pairs {x i , y i } N i=1 are available (Figure 2, left), e.g., [11, 19, 22, 23, 28, 33, 45, 56, 58,62]. 
多年来在计算机视觉，图像处理，计算摄影和图形方面的研究已经在有监督的环境下产生了功能强大的翻译系统，其中示例图像对{xi，yi} N i = 1可用（图2，左），例如[ 11、19、22、23、28、33、45、56、58、62]。

However, obtaining paired training data can be difficult and expensive. For example, only a couple of datasets exist for tasks like semantic segmentation (e.g., [4]), and they are relatively small.
多年来在计算机视觉，图像处理，计算摄影和图形方面的研究已经在有监督的环境下产生了功能强大的翻译系统，其中示例图像对{xi，yi} N i = 1可用（图2，左），例如[ 11、19、22、23、28、33、45、56、58、62]。

然而，获得成对的训练数据可能是困难且昂贵的。例如，仅存在用于语义分割等任务的几个数据集（例如[4]），并且它们相对较小。

Obtaining input-output pairs for graphics tasks like artistic stylization can be even more difficult since the desired output is highly complex, typically requiring artistic authoring. 
由于所需的输出高度复杂（通常需要艺术创作），因此获取图形任务（如艺术风格）的输入输出对可能会更加困难。

For many tasks, like object transfiguration (e.g., zebra↔horse, Figure 1 top-middle), the desired output is not even well-defined.
对于许多任务，例如对象变形（例如，斑马，图1居中），所需的输出甚至都没有明确定义。

We therefore seek an algorithm that can learn to translate between domains without paired input-output examples (Figure 2, right). 
因此，我们寻求一种无需对输入/输出示例进行配对即可学会在域之间进行翻译的算法（右图2）。

We assume there is some underlying relationship between the domains – for example, that they are two different renderings of the same underlying scene – and seek to learn that relationship.
我们假设这些域之间存在某种潜在的关系-例如，它们是同一基础场景的两个不同渲染-并试图学习这种关系。

Although we lack supervision in the form of paired examples, we can exploit supervision at the level of sets: we are given one set of images in domain X and a different set in domain Y . 
尽管我们缺乏成对示例形式的监督，但是我们可以在集合级别上利用监督：我们在域X中获得了一组图像，在域Y中获得了一组不同的图像。



















---