## 摘要

　　人们普遍同意，成功地训练深度网络需要数千个带注释的训练样本。在本文中，我们提出了一种网络和训练策略，该策略依靠大量使用数据增强功能来更有效地使用可用的带注释的样本。该体系结构包括捕获上下文的收缩路径和实现精确定位的对称扩展路径。我们展示了这样的网络可以从很少的图像进行端到端训练，并且在ISBI挑战方面优于现有的最佳方法（滑动窗口卷积网络），可用于分割电子显微镜堆栈中的神经元结构。使用在透射光显微镜图像（相差和DIC）上训练过的同一网络，我们在这些类别中赢得了2015年ISBI细胞跟踪挑战赛的冠军。而且，网络速度很快。在最新的GPU上，对512x512图像进行分割所需的时间不到一秒钟。

完整的实现（基于Caffe）和受过培训的网络可在http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net上获得。

---


## 引言