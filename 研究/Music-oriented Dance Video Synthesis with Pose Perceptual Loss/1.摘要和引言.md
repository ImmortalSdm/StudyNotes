## 摘要

我们提出了一种基于学习的带姿势感知损失的音乐视频自动生成方法。

我们的方法可以产生一个逼真的舞蹈视频，符合几乎任何给定音乐的节奏和韵律。

为了实现这一点，我们首先从音乐中生成人体骨架序列，然后将学习到的姿势映射到外观映射，生成最终的视频。

在骨架序列生成阶段，我们利用两个鉴别器捕捉序列的不同方面，并提出一种新的pose perceptual loss来产生自然舞蹈。

此外，我们还提出了一种新的跨模态评价方法来评价舞蹈的质量，它能够估计音乐和舞蹈两种形态之间的相似性。

最后，通过一个用户研究表明，用该方法合成的舞蹈视频能产生令人惊讶的逼真效果。


---

## 1.引言

虽然这些音乐视频是由专业艺术家制作的，但我们想知道智能系统是否能够自动生成个性化和创造性的音乐视频。

在这项工作中，我们研究的是几乎任何音乐都可以自动生成舞蹈音乐视频。

我们的目标是合成一个连贯的，照片逼真的舞蹈视频，符合给定的音乐。

在图1中，我们展示了一些我们合成的舞蹈视频的图像，其中给出了Cosmic Girls的音乐“I Wish”。

由于各种技术原因，舞蹈视频合成任务具有挑战性。

首先，舞蹈动作和背景音乐之间的映射是模棱两可的：不同的艺术家可以在同一音乐中创作出不同的舞蹈动作。这表明，一个具有l1或l2距离的简单机器学习模型很难捕捉到舞蹈和音乐之间的关系。

其次，人体舞蹈空间的建模技术难度较大。模型应避免产生非自然的舞蹈动作。即使是稍微偏离正常人的姿势也可能显得不自然。

第三，我们的任务没有高质量的数据集。以前的运动数据集[18，33]主要集中在动作识别上。Tang等人。[35]为我们的任务提供3D关节数据集。然而，当我们尝试使用它时，我们会遇到舞蹈动作和音乐不一致的错误。

目前，网上有大量的带有舞蹈的音乐视频，可以用来完成音乐视频的生成任务。为了为我们的任务建立一个数据集，我们应用OpenPose[4,5,42]从在线视频中获取舞蹈骨架序列。然而，OpenPose获取的骨骼序列噪声很大，一些估计的人体姿态是不准确的。通过删除不准确的姿势来纠正这样的数据集非常耗时，因此不适合广泛的应用。此外，在以往的工作中，仅使用l1或l2距离来训练网络[19,35,43]，这被[24]证明忽略了某些特定的运动特性。为了解决这些问题，我们提出了一种新的pose perceptual loss方法，使得我们的模型可以根据OpenPose获得的噪声数据（不完美的人体姿态）进行训练。

在文献中，通过使用音乐作为查询在数据库中搜索舞蹈动作，对舞蹈合成进行了深入研究[1，16，31]。这些方法不能很好地推广到训练数据之外的音乐，缺乏创造性，这是舞蹈最不可或缺的因素。为了克服这些障碍，我们选择生成对抗网络（generative atterial network，GAN）[12]来处理跨模式映射。
然而，Cai等人。[3] 结果表明，人体姿态约束过于复杂，难以用直接GAN方法训练的端到端模型捕捉。因此，我们分别提出了局部相关性（local coherence）和全局一致性（global harmony）两种判别器。

综上所述，我们的工作贡献是：

1、在提出的姿势感知损失的情况下，我们的模型可以在一个嘈杂的数据集（没有人类标签）上训练，以合成几乎符合任何给定音乐的逼真舞蹈视频。

2、使用局部时间鉴别器和全局内容鉴别器，我们的框架可以生成一个连贯的舞蹈骨架序列，与音乐的长度、节奏和情感相匹配。

3、在我们的任务中，我们建立了一个包含成对音乐和骨架序列的数据集，并将其公开用于研究。为了评估我们的模型，我们还提出了一种新的跨模态评估方法来衡量音乐和舞蹈骨架序列之间的相似性。