## 设定  
#### 基准线
我们将我们的方法与其他几种模型进行比较。
##### 总是预测中位姿势
演讲者大部分时间都处于休息位置[22]，因此预测演讲者的中位姿势可以作为高质量的基线。有关每个扬声器的静止位置的外观，请参见图2。
##### 预测随机选择的手势
在此基准中，我们从同一说话者的训练集中随机选择一个不同的手势序列（与输入话语不对应），并将其用作我们的预测。尽管我们不希望这种方法在量化上表现良好，但是有理由认为它会产生质感诱人的动作：这是真实的说话人手势，要告诉他们是假的，唯一的方法就是评估其对应的效果。音频。
##### 最近邻
代替从同一说话者选择完全随机的手势序列，我们可以将音频用作相似提示。对于输入音频轨道，我们使用预训练的音频功能找到与扬声器最近的邻居，并传递其相应的运动。为了表示音频，我们使用在AudioSet [17]上预先训练的最新VGGish功能嵌入[20]，并在归一化功能上使用余弦距离。
##### RNN
我们进一步将运动预测与Shlizerman等人提出的RNN架构进行比较。与我们类似，Shlizerman等。从2D骨骼关键点空间中的音频预测手臂和手部动作。但是，尽管我们的模型是带有对数-梅尔频谱图输入的卷积神经网络，但他们的模型使用的是1层LSTM模型，该模型采用MFCC特征（低维，手工制作的音频特征表示）作为输入。我们评估了这两种特征类型，发现对于[37]，MFCC特征在所有说话者上的表现均优于对数mel频谱图特征。因此，我们在实验中使用它们的原始MFCC功能。为了与我们自己的模型保持一致，我们没有像在PCA要素上那样测量L2距离，而是添加了额外的隐藏层并使用L1距离。
##### 我们的，没有GAN
最后，作为消融，我们将完整模型与单独的翻译体系结构的预测进行了比较，而没有对抗性鉴别器。
#### 评估指标
我们主要的量化评估指标是比较不同模型的L1回归损失。我们另外根据正确关键点（PCK）的百分比报告结果[42]，这是一种广泛接受的姿势检测指标。在此，如果预测的关键点落在地面真实关键点的αmax（h，w）个像素之内，则定义为正确，其中h和w分别是人员边界框的高度和宽度。我们将PCK值看得一清二楚，因为它并不是针对部分可见说话者的手势预测而设计的。首先，与L1不同，PCK不是线性的，并且正确性评分在硬阈值之外降至零。由于我们的目标不是预测地面真实运动，而是将其用作训练信号，因此L1更适合衡量我们的平均表现。其次，PCK对较大的手势动作敏感，因为正确半径取决于讲话者手臂的跨度。第三，对人的边界框的依赖引入了人为的敏感性，即每个人在框架中显示了多少，以及他们是坐着还是站着。虽然[42]建议对于有完整人员的数据，α= 0.1，对于只有一半人可见的数据，α= 0.2，但我们对α= 0.1，0.2取平均值，并在补充资料中显示完整结果。
## 定量评估
我们使用定量指标将方法的结果与基线进行比较。为了评估我们的结果是否令人信​​服，我们进行了一项用户研究。
最后，我们询问所预测的手势是否是特定于人的，并且输入语音是否确实比手势的初始姿势更好地预测运动    
## 定性结果
我们定性地将语音与手势翻译结果与图5中的基线和地面真相手势序列进行比较。请参考我们的补充视频结果，以更好地传达时间信息
