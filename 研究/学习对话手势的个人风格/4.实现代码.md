[提供的源代码](https://github.com/amirbar/speech2gesture)

训练：
```
audio_to_multiple_pose_gan.train
```

对验证集中的随机样本进行推断：
```
audio_to_multiple_pose_gan.predict_to_videos
```

对音频样本进行预测：
```
audio_to_multiple_pose_gan.predict_audio
```

---
### 建立poseGAN模型

> 生成对抗网络GAN由生成器generator和鉴别器discriminator组成
，当 discriminator 无法分辨生成的图片和真实图片，这个网络就拟合了。

```
python -m audio_to_multiple_pose_gan.train --gans 1 --name test_run --arch_g audio_to_pose_gans --arch_d D_patchgan --speaker oliver --output_path ../tmp --train_csv ../train.csv
```

PoseGAN的self参数|备注
-|-
args|配置参数
sess|tensorflow会话
real_pose|
fake_pose|
pose_regloss|运动或姿势上的回归损失
G_gan_loss|
fake_pose_score|
real_pose_score|
is_training|
D_loss|训练全局鉴别器D的损失
G_gan_loss|全局鉴别器D训练生成器的损失
train_D|训练全局鉴别器D
G_loss|统计训练生成器的所有损失




PoseGAN的self.args参数|值区间|默认值|备注
-|-|-|-
lambda_gan|float|1|multiplier for the GAN loss (versus the regression loss) for the generator. generator_loss = regression_loss + lambda_gan * GAN_loss
lambda_d|float|1|
d_input|motion / pose|motion|运动或姿势上的回归损失
reg_loss|motion / pose / both|pose
reg_loss_type|l1 / l2|l1|回归类型
lambda_motion_reg_loss|
gans|
name|
checkpoint|
itr_d|
itr_g|
lr_g|
lr_d|
arch_g|audio_to_pose_gans / audio_to_pose|audio_to_pose_gans
arch_d|D_patchgan|D_patchgan
norm|
train_csv|
speaker|
output_path|
config|
output_videos|integer|1
batch_size||32|在一轮训练中，单次训练的数据数量
epochs||300|训练轮数
seq_len|
sample|



---

### 训练poseGAN模型

---
### 用poseGAN模型进行推理











---
