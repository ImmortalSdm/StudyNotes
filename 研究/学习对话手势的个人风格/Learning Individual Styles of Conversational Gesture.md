# 学习对话手势的个人风格
Learning Individual Styles of Conversational Gesture

## 2.相关工作

- 手语和象征性手势识别(Sign language and emblematic gesture recognition)

大量的计算机视觉工作涉及从视频中识别手语手势。
这包括使用视频成绩单作为监督的薄弱来源的方法[3]，以及基于CNN [33，24]和RNN [13]的最新方法。也有一些工作可以识别象征性的手势和面部手势[16、14]，头部手势[31]和同声手势[34]。相比之下，我们的目标是从音频预测同语音手势。

- 对话代理(Conversational agents)

研究人员提出了多种方法来生成合理的手势，特别是对于会话代理的应用[8]。
在早期的工作中，Cassell等人。
[7]提出了一种基于手动定义的规则来指导手臂/手部动作的系统。
随后的基于规则的系统[25]提出了通过注释来表达手势的新方法。
与我们的方法更紧密相关的方法是从语音和文本中学习手势的方法，而无需作者手动指定规则。
值得注意的是，[9]使用口语文本的自然语言处理来合成手势，而Neff [32]提出了一种用于做出特定于人的手势的系统。
莱文等。
[28]学会了使用HMM将声学韵律特征映射到运动。
后来的工作[27]将这种方法扩展为使用强化学习和语音识别，结合文本的声学分析[29]，创建基于规则的混合混合系统[36]以及使用受限的Boltzmann机器进行推理[11]。
由于这些方法的目标是为虚拟代理生成动作，因此它们使用实验室录制的音频，文本和动作捕获。这使他们能够使用简化的假设，这些假设为像我们这样的野生视频分析提供了挑战：例如，[28]需要精确的3D姿势，并假设运动发生在音节边界上，[11]则假设手势由手腕向上运动启动。与这些方法相比，我们的方法在训练过程中没有明确使用任何文本或语言信息-它从原始的视听对应关系中学习手势-也没有使用手定义的手势类别：手臂/手的姿势是直接从音频中预测的。

- 可视化预测手势(Visualizing predicted gestures)

可视化手势的最常见方式之一就是使用它们来为3D化身动画[40、27、19]。由于我们的研究工作是针对无法获得3D数据的野生视频的个性化手势，因此我们使用了Bregler等人启发的数据驱动的综合方法。[2]。为此，我们使用Chan等人的“从视频到视频的姿势”方法。[10]，它使用条件生成对抗网络（GAN）从姿势合成人体视频。

- 声音和视觉(Sound and vision)

Aytar等。
[1]利用自然现象中视觉和音频信号的同步，通过传递来自视觉领域经过训练的判别模型的知识，从未标记的野生视频中学习声音表示。
音频和视频功能的同步也可以用于合成。
Langlois等。
[26]尝试通过生成物体掉落或跌落的刚体动画来优化此类同步事件，这些动画在时间上将输入的声波与所需的接触事件序列与地面进行匹配。
最近，Shlizerman等人。
[37]根据输入的信息对3D化身的手进行了动画处理。
但是，他们的重点是音乐演奏，而不是手势，因此，可能的动作空间有限（例如，小提琴弓的曲折运动）。
此外，虽然音乐是由产生音乐的动作（与音乐同步）唯一定义的，但手势既不是语音所独有的，也不是与语音发声同步的。
在给定音频输入的情况下，一些作品专注于合成说话人的视频的特定任务。
Chung等。
[12]通过学习面部和音频的联合嵌入，从说话者的静止图像和输入的语音片段中生成说话的面部图像。
同样，[39]通过使用递归神经网络将语音音频映射到嘴巴形状，然后将合成的嘴唇嵌入地面真人面部视频中，来合成奥巴马说新颖单词的视频。
虽然这两种方法都可以通过生成说不同人的话的面孔来创建伪造内容，但我们专注于针对动画相同说话者言语而优化的单人模型。
最重要的是，由于手势与语音是异步的，多模式的且针对特定的人，因此从语音生成手势而不是嘴唇动作更为复杂。





## 结论
人类通过视觉和声音进行交流，但是这些方式之间的联系仍然不清楚[22]。在本文中，我们提出了从“狂野”语音中预测特定于人的手势的任务，作为研究这些沟通渠道之间联系的一种计算手段。我们创建了一个针对特定人群的视频数据集，并使用该数据集训练了一个模型来预测语音手势。在实验评估中，我们的模型优于其他方法。
尽管在这些任务上表现出色，但我们的模型仍存在局限性，可以通过结合其他工作来解决。例如，使用音频作为输入有其好处，因为音频是一种丰富的表示形式，其中包含有关韵律，音高，语调，音色，节奏，音调等信息。然而，音频不直接编码高级语言的语义可以允许我们预测某些类型的手势（例如metaphorics）的，也不说话人的语音从其它声音（例如AU dience笑声）分离。其次，我们将姿势估计视为基本事实，这会引入大量噪声，尤其是在说话者的手指上。
我们认为我们的工作是朝对话手势进行计算分析的一步，并为进一步研究打开了三个可能的方向。
第一个是使用手势作为视频分析的表示形式：同语音手势和手臂动作自然成为视频预测任务的目标。
第二种是使用野外手势作为训练对话代理的方法：我们基于GAN [10]提出了一种可视化手势预测的可视化方法，但遵循经典工作[8]，这些方法 预测还可以用于驱动虚拟代理的运动。
最后，我们的方法是从音频预测运动的少数少数尝试之一。
跨模式翻译任务是进一步研究的沃土













---
